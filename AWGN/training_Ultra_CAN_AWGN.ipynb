{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "OEAfQA05D6ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import platform\n",
        "from tensorflow.keras import layers, optimizers, losses, models, Input, Model\n",
        "import time # Per misurare il tempo di training\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Per l'early stopping\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Per mostrare una barra di progresso"
      ],
      "metadata": {
        "id": "cAkyZrEzu97V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set seeds for random operations."
      ],
      "metadata": {
        "id": "AujxZNQWMBuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Impostazione del Seed Globale all'inizio del tuo script ---\n",
        "# Questo è il punto chiave per la riproducibilità di TUTTO ciò che segue.\n",
        "MASTER_RANDOM_SEED = 42\n",
        "np.random.seed(MASTER_RANDOM_SEED)\n",
        "random.seed(MASTER_RANDOM_SEED) # Imposta anche il seed per la libreria 'random' di Python se la usi\n",
        "tf.random.set_seed(MASTER_RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(MASTER_RANDOM_SEED) # Per operazioni basate su hash (es. ordine dei dizionari)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Forza operazioni deterministiche in TensorFlow 2.x"
      ],
      "metadata": {
        "id": "uXGzTxrOME1z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the HW Specs."
      ],
      "metadata": {
        "id": "OBZ65HW9CLdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Dettagli dell'Architettura Hardware della Sessione Colab ---\\n\")\n",
        "\n",
        "# --- 1. Dettagli CPU ---\n",
        "print(\"--- Dettagli CPU ---\")\n",
        "!lscpu\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 2. Dettagli RAM (Memoria) ---\n",
        "print(\"--- Dettagli RAM (Memoria) ---\")\n",
        "!cat /proc/meminfo | grep MemTotal\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 3. Dettagli Spazio su Disco ---\n",
        "print(\"--- Dettagli Spazio su Disco ---\")\n",
        "!df -h /\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 4. Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
        "print(\"--- Dettagli Acceleratore Hardware (GPU/TPU) ---\")\n",
        "try:\n",
        "    tpu_address = os.environ.get('COLAB_TPU_ADDR')\n",
        "    if tpu_address:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(f\"Tipo Acceleratore: TPU (indirizzo: {tpu_address})\")\n",
        "        print(\"Dispositivi TPU disponibili:\")\n",
        "        for device in tf.config.list_logical_devices('TPU'):\n",
        "            print(f\"  - {device.name}\")\n",
        "    else:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            print(f\"Tipo Acceleratore: GPU\")\n",
        "            for gpu in gpus:\n",
        "                print(f\"  - Dispositivo GPU rilevato: {gpu.name}\")\n",
        "            print(\"\\nDettagli GPU specifici (da `!nvidia-smi`):\")\n",
        "            !nvidia-smi\n",
        "        else:\n",
        "            print(\"Tipo Acceleratore: Nessuna GPU o TPU rilevata (in uso CPU)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Si è verificato un errore durante la rilevazione dell'acceleratore: {e}\")\n",
        "    print(\"Tentativo di rilevare i dispositivi TensorFlow standard:\")\n",
        "    devices = tf.config.list_logical_devices()\n",
        "    if devices:\n",
        "        for device in devices:\n",
        "            print(f\"  - Dispositivo rilevato: {device.name}, Tipo: {device.device_type}\")\n",
        "    else:\n",
        "        print(\"Nessun dispositivo TensorFlow rilevato.\")\n",
        "\n",
        "print(\"\\n--- Analisi Dettagli Hardware Completata ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBhq145cCO9I",
        "outputId": "6d3c1fe7-3797-4c92-8cdb-f7924a0605c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dettagli dell'Architettura Hardware della Sessione Colab ---\n",
            "\n",
            "--- Dettagli CPU ---\n",
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:           6\n",
            "    Model:                79\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             0\n",
            "    BogoMIPS:             4399.99\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm r\n",
            "                          dseed adx smap xsaveopt arat md_clear arch_capabilitie\n",
            "                          s\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     256 KiB (1 instance)\n",
            "  L3:                     55 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n",
            "\n",
            "\n",
            "--- Dettagli RAM (Memoria) ---\n",
            "MemTotal:       13289416 kB\n",
            "\n",
            "\n",
            "--- Dettagli Spazio su Disco ---\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   38G   75G  34% /\n",
            "\n",
            "\n",
            "--- Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
            "Tipo Acceleratore: GPU\n",
            "  - Dispositivo GPU rilevato: /physical_device:GPU:0\n",
            "\n",
            "Dettagli GPU specifici (da `!nvidia-smi`):\n",
            "Sun Jul 20 06:37:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "--- Analisi Dettagli Hardware Completata ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect To Gdrive to store the datasets created."
      ],
      "metadata": {
        "id": "X46EKvDxpZ-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7J7tQfWpjXc",
        "outputId": "83cdb762-ecb0-4909-901a-da68f693dc37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the paths"
      ],
      "metadata": {
        "id": "YGVsmzeNKtlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorsi dataset\n",
        "paths = {\n",
        "    \"0-20\": {\n",
        "        \"train\": \"/content/drive/MyDrive/GitHub/AWGN/dataset/training_0-20_SNR.npz\",\n",
        "        \"val\": \"/content/drive/MyDrive/GitHub/AWGN/dataset/validation_0-20_SNR.npz\",\n",
        "    },\n",
        "    \"11-15\": {\n",
        "        \"train\": \"/content/drive/MyDrive/GitHub/AWGN/dataset/training_11-15_SNR.npz\",\n",
        "        \"val\": \"/content/drive/MyDrive/GitHub/AWGN/dataset/validation_11-15_SNR.npz\",\n",
        "    }\n",
        "}\n",
        "\n",
        "# Directory salvataggio modelli\n",
        "save_dir = \"/content/drive/MyDrive/GitHub/AWGN/trained_models/benchmarks\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "G7Qs-TmuKwOY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the datasets."
      ],
      "metadata": {
        "id": "gD7ssM5qLY-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filepath):\n",
        "    \"\"\"\n",
        "    Carica i dati X e y da un file .npz.\n",
        "    Si aspetta che il file contenga 'X_train' o 'X_val' e 'y_train' o 'y_val'.\n",
        "    \"\"\"\n",
        "    data = np.load(filepath)\n",
        "\n",
        "    # Controlla se le chiavi per il training sono presenti\n",
        "    if 'X_train' in data and 'y_train' in data:\n",
        "        print(f\"  Caricato Training data da: {filepath}\")\n",
        "        return data['X_train'], data['y_train']\n",
        "    # Altrimenti, controlla se le chiavi per la validation sono presenti\n",
        "    elif 'X_val' in data and 'y_val' in data:\n",
        "        print(f\"  Caricato Validation data da: {filepath}\")\n",
        "        return data['X_val'], data['y_val']\n",
        "    else:\n",
        "        # Se nessuna delle combinazioni attese è trovata, solleva un errore\n",
        "        raise ValueError(f\"Il file {filepath} non contiene i dati X e y attesi (né 'X_train'/'y_train' né 'X_val'/'y_val'). \"\n",
        "                         f\"Chiavi trovate: {list(data.keys())}\")"
      ],
      "metadata": {
        "id": "VJcjv-xvLcA5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark models definition"
      ],
      "metadata": {
        "id": "-chXzhHELfQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzioni modello\n",
        "\n",
        "def get_ultracan_model(input_shape, model_name='ULTRA-CAN'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Reshape per conv1D\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape\")(inputs)\n",
        "\n",
        "    # Leggera CNN\n",
        "    x = layers.Conv1D(8, kernel_size=3, padding='same', activation='relu', name=\"cnn1\")(x)\n",
        "    x = layers.Conv1D(8, kernel_size=3, padding='same', activation='relu', name=\"cnn2\")(x)\n",
        "\n",
        "    # Temporal convolution (tipo TCN semplificato con dilatazione)\n",
        "    x = layers.Conv1D(8, kernel_size=3, dilation_rate=2, padding='same', activation='relu', name=\"tcn1\")(x)\n",
        "\n",
        "    # Attention leggera (tipo global self-attention)\n",
        "    attention = layers.Permute((2,1), name=\"permute_for_attention\")(x)\n",
        "    attention = layers.Dense(input_shape[0], activation='softmax', name=\"attention_weights\")(attention)\n",
        "    attention = layers.Permute((2,1), name=\"unpermute\")(attention)\n",
        "    x = layers.Multiply(name=\"apply_attention\")([x, attention])\n",
        "\n",
        "    # Pooling e FC finale\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_avg_pool\")(x)\n",
        "    x = layers.Dense(32, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_tdnn_model(input_shape, model_name='TDNN OFDM-DCSK'):\n",
        "    # Dal paper: \"Reliable and Secure Deep Learning-Based OFDM-DCSK Transceiver Design Without Delivery of Reference Chaotic Sequences\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_length = input_shape[0]\n",
        "    x = layers.Reshape((input_length, 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(4, 2, activation='relu', padding='same', name=\"tdnn_conv1\")(x)\n",
        "    x = layers.Conv1D(8, 4, activation='relu', padding='same', name=\"tdnn_conv2\")(x)\n",
        "    x = layers.Conv1D(16, 8, activation='relu', padding='same', name=\"tdnn_conv3\")(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False), name=\"bidirectional_lstm\")(x)\n",
        "    x = layers.Dense(128, name=\"fc1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"batch_norm\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu_fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name='DNN_Aided_Demodulator')\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_mc_dlcs_model(input_shape, model_name='MC-DLCSK'):\n",
        "    # Dal paper: \"A Multi-Carrier Deep Learning CSK Communication System\"\n",
        "    if input_shape[0] % 2 != 0:\n",
        "        raise ValueError(\"input_shape deve essere pari per MC-DLCSK\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_lstm\")(inputs)\n",
        "    x = layers.Bidirectional(layers.LSTM(50, return_sequences=False), name=\"bidirectional_lstm\")(x)\n",
        "    x = layers.Dense(64, activation='relu', name=\"fc1_relu\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_lstm_dnn_model(input_shape, model_name='LSTM_DNN_OFDM_DCSK'):\n",
        "    # Dal paper: \"Intelligent and Reliable Deep Learning LSTM Neural Networks-Based OFDM-DCSK Demodulation Design\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    if len(input_shape) == 1:\n",
        "        x = layers.Reshape((1, input_shape[0]))(inputs)\n",
        "    elif len(input_shape) == 2:\n",
        "        x = inputs\n",
        "    else:\n",
        "        raise ValueError(\"input_shape deve essere 1D o 2D\")\n",
        "    x = layers.LSTM(19, return_sequences=True)(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(38, activation='relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "models_dict = {\n",
        "    \"Ultra-CAN\": get_ultracan_model,\n",
        "    #\"TDNN OFDM-DCSK\": get_tdnn_model,\n",
        "    #\"MC-DLCSK\": get_mc_dlcs_model,\n",
        "    #\"LSTM_DNN_OFDM_DCSK\": get_lstm_dnn_model\n",
        "}"
      ],
      "metadata": {
        "id": "5UoABDP2KlQI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training..."
      ],
      "metadata": {
        "id": "HqhoJHu1Lks5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addestramento\n",
        "for snr_range, datasets in paths.items():\n",
        "    x_train, y_train = load_dataset(datasets['train'])\n",
        "    x_val, y_val = load_dataset(datasets['val'])\n",
        "\n",
        "    for model_name, builder in models_dict.items():\n",
        "        print(f\"\\nAddestramento modello: {model_name} | SNR range: {snr_range}\")\n",
        "        model = builder(input_shape=x_train.shape[1:])\n",
        "\n",
        "        callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "        start_time = time.time() # Registra il tempo di inizio training\n",
        "\n",
        "        model.fit(\n",
        "            x_train, y_train,\n",
        "            validation_data=(x_val, y_val),\n",
        "            epochs=30,\n",
        "            batch_size=32,\n",
        "            callbacks=[callback],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        end_time = time.time() # Registra il tempo di fine training\n",
        "        total_training_time = end_time - start_time\n",
        "\n",
        "        print(f\"Training completato.\")\n",
        "        print(f\"Tempo totale di training: {total_training_time:.2f} secondi.\") # Stampa il tempo totale\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_awgn_snr_{snr_range}.h5\")\n",
        "        model.save(save_path)\n",
        "        print(f\"Salvato modello in: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u1TCwRHLmHk",
        "outputId": "a9721682-0c73-4f6b-8690-be3e184abc3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/AWGN/dataset/training_0-20_SNR.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/AWGN/dataset/validation_0-20_SNR.npz\n",
            "\n",
            "Addestramento modello: Ultra-CAN | SNR range: 0-20\n",
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8331 - loss: 0.2962 - val_accuracy: 0.9998 - val_loss: 9.6936e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 8.6382e-04 - val_accuracy: 0.9961 - val_loss: 0.0101\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9994 - val_loss: 0.0018\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9991 - val_loss: 0.0030\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9992 - val_loss: 0.0017\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9990 - val_loss: 0.0038\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9996 - val_loss: 0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 200.40 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/AWGN/trained_models/benchmarks/Ultra-CAN_awgn_snr_0-20.h5\n",
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/AWGN/dataset/training_11-15_SNR.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/AWGN/dataset/validation_11-15_SNR.npz\n",
            "\n",
            "Addestramento modello: Ultra-CAN | SNR range: 11-15\n",
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8672 - loss: 0.2625 - val_accuracy: 0.9874 - val_loss: 0.0272\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9997 - val_loss: 0.0012\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 7.0956e-04 - val_accuracy: 1.0000 - val_loss: 4.7074e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.4004e-05 - val_accuracy: 1.0000 - val_loss: 1.3232e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.5821e-05 - val_accuracy: 1.0000 - val_loss: 3.1215e-06\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.7850e-06 - val_accuracy: 1.0000 - val_loss: 1.1080e-06\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 2.4452e-04 - val_accuracy: 0.9997 - val_loss: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 9.5500e-04 - val_accuracy: 1.0000 - val_loss: 1.1958e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.7960e-05 - val_accuracy: 1.0000 - val_loss: 1.9061e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4237e-06 - val_accuracy: 1.0000 - val_loss: 1.0636e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.5200e-06 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
            "Epoch 12/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 7.4390e-04 - val_accuracy: 1.0000 - val_loss: 3.4845e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 2.4601e-04 - val_accuracy: 0.9997 - val_loss: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 1.3656e-04 - val_accuracy: 1.0000 - val_loss: 3.1448e-06\n",
            "Epoch 15/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8821e-05 - val_accuracy: 0.9999 - val_loss: 3.9746e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.3558e-05 - val_accuracy: 0.9999 - val_loss: 4.9762e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 267.06 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/AWGN/trained_models/benchmarks/Ultra-CAN_awgn_snr_11-15.h5\n"
          ]
        }
      ]
    }
  ]
}