{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "OEAfQA05D6ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import platform\n",
        "from tensorflow.keras import layers, optimizers, losses, models, Input, Model\n",
        "import time # Per misurare il tempo di training\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Per l'early stopping\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Per mostrare una barra di progresso"
      ],
      "metadata": {
        "id": "cAkyZrEzu97V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set seeds for random operations."
      ],
      "metadata": {
        "id": "AujxZNQWMBuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Impostazione del Seed Globale all'inizio del tuo script ---\n",
        "# Questo è il punto chiave per la riproducibilità di TUTTO ciò che segue.\n",
        "MASTER_RANDOM_SEED = 42\n",
        "np.random.seed(MASTER_RANDOM_SEED)\n",
        "random.seed(MASTER_RANDOM_SEED) # Imposta anche il seed per la libreria 'random' di Python se la usi\n",
        "tf.random.set_seed(MASTER_RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(MASTER_RANDOM_SEED) # Per operazioni basate su hash (es. ordine dei dizionari)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Forza operazioni deterministiche in TensorFlow 2.x"
      ],
      "metadata": {
        "id": "uXGzTxrOME1z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the HW Specs."
      ],
      "metadata": {
        "id": "OBZ65HW9CLdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Dettagli dell'Architettura Hardware della Sessione Colab ---\\n\")\n",
        "\n",
        "# --- 1. Dettagli CPU ---\n",
        "print(\"--- Dettagli CPU ---\")\n",
        "!lscpu\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 2. Dettagli RAM (Memoria) ---\n",
        "print(\"--- Dettagli RAM (Memoria) ---\")\n",
        "!cat /proc/meminfo | grep MemTotal\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 3. Dettagli Spazio su Disco ---\n",
        "print(\"--- Dettagli Spazio su Disco ---\")\n",
        "!df -h /\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 4. Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
        "print(\"--- Dettagli Acceleratore Hardware (GPU/TPU) ---\")\n",
        "try:\n",
        "    tpu_address = os.environ.get('COLAB_TPU_ADDR')\n",
        "    if tpu_address:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(f\"Tipo Acceleratore: TPU (indirizzo: {tpu_address})\")\n",
        "        print(\"Dispositivi TPU disponibili:\")\n",
        "        for device in tf.config.list_logical_devices('TPU'):\n",
        "            print(f\"  - {device.name}\")\n",
        "    else:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            print(f\"Tipo Acceleratore: GPU\")\n",
        "            for gpu in gpus:\n",
        "                print(f\"  - Dispositivo GPU rilevato: {gpu.name}\")\n",
        "            print(\"\\nDettagli GPU specifici (da `!nvidia-smi`):\")\n",
        "            !nvidia-smi\n",
        "        else:\n",
        "            print(\"Tipo Acceleratore: Nessuna GPU o TPU rilevata (in uso CPU)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Si è verificato un errore durante la rilevazione dell'acceleratore: {e}\")\n",
        "    print(\"Tentativo di rilevare i dispositivi TensorFlow standard:\")\n",
        "    devices = tf.config.list_logical_devices()\n",
        "    if devices:\n",
        "        for device in devices:\n",
        "            print(f\"  - Dispositivo rilevato: {device.name}, Tipo: {device.device_type}\")\n",
        "    else:\n",
        "        print(\"Nessun dispositivo TensorFlow rilevato.\")\n",
        "\n",
        "print(\"\\n--- Analisi Dettagli Hardware Completata ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBhq145cCO9I",
        "outputId": "db53a115-bea0-4d06-dc2d-6b739b18107c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dettagli dell'Architettura Hardware della Sessione Colab ---\n",
            "\n",
            "--- Dettagli CPU ---\n",
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:           6\n",
            "    Model:                85\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             3\n",
            "    BogoMIPS:             4000.35\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm m\n",
            "                          px avx512f avx512dq rdseed adx smap clflushopt clwb av\n",
            "                          x512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsave\n",
            "                          s arat md_clear arch_capabilities\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     1 MiB (1 instance)\n",
            "  L3:                     38.5 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n",
            "\n",
            "\n",
            "--- Dettagli RAM (Memoria) ---\n",
            "MemTotal:       13289424 kB\n",
            "\n",
            "\n",
            "--- Dettagli Spazio su Disco ---\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   38G   75G  34% /\n",
            "\n",
            "\n",
            "--- Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
            "Tipo Acceleratore: GPU\n",
            "  - Dispositivo GPU rilevato: /physical_device:GPU:0\n",
            "\n",
            "Dettagli GPU specifici (da `!nvidia-smi`):\n",
            "Sun Jul 20 06:40:44 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "--- Analisi Dettagli Hardware Completata ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect To Gdrive to store the datasets created."
      ],
      "metadata": {
        "id": "X46EKvDxpZ-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7J7tQfWpjXc",
        "outputId": "fee5f2bd-9ac4-481d-8811-f33e0c92db37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the paths"
      ],
      "metadata": {
        "id": "YGVsmzeNKtlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorsi dataset\n",
        "paths = {\n",
        "    \"0-20\": {\n",
        "        \"train\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/training_0-20_SNR.npz\",\n",
        "        \"val\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_0-20_SNR.npz\",\n",
        "    },\n",
        "    \"11-15\": {\n",
        "        \"train\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR.npz\",\n",
        "        \"val\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR.npz\",\n",
        "    }\n",
        "}\n",
        "\n",
        "# Directory salvataggio modelli\n",
        "save_dir = \"/content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "G7Qs-TmuKwOY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the datasets."
      ],
      "metadata": {
        "id": "gD7ssM5qLY-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filepath):\n",
        "    \"\"\"\n",
        "    Carica i dati X e y da un file .npz.\n",
        "    Si aspetta che il file contenga 'X_train' o 'X_val' e 'y_train' o 'y_val'.\n",
        "    \"\"\"\n",
        "    data = np.load(filepath)\n",
        "\n",
        "    # Controlla se le chiavi per il training sono presenti\n",
        "    if 'X_train' in data and 'y_train' in data:\n",
        "        print(f\"  Caricato Training data da: {filepath}\")\n",
        "        return data['X_train'], data['y_train']\n",
        "    # Altrimenti, controlla se le chiavi per la validation sono presenti\n",
        "    elif 'X_val' in data and 'y_val' in data:\n",
        "        print(f\"  Caricato Validation data da: {filepath}\")\n",
        "        return data['X_val'], data['y_val']\n",
        "    else:\n",
        "        # Se nessuna delle combinazioni attese è trovata, solleva un errore\n",
        "        raise ValueError(f\"Il file {filepath} non contiene i dati X e y attesi (né 'X_train'/'y_train' né 'X_val'/'y_val'). \"\n",
        "                         f\"Chiavi trovate: {list(data.keys())}\")"
      ],
      "metadata": {
        "id": "VJcjv-xvLcA5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark models definition"
      ],
      "metadata": {
        "id": "-chXzhHELfQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzioni modello\n",
        "\n",
        "def get_ultracan_model(input_shape, model_name='ULTRA-CAN'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Reshape per conv1D\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape\")(inputs)\n",
        "\n",
        "    # Leggera CNN\n",
        "    x = layers.Conv1D(8, kernel_size=3, padding='same', activation='relu', name=\"cnn1\")(x)\n",
        "    x = layers.Conv1D(8, kernel_size=3, padding='same', activation='relu', name=\"cnn2\")(x)\n",
        "\n",
        "    # Temporal convolution (tipo TCN semplificato con dilatazione)\n",
        "    x = layers.Conv1D(8, kernel_size=3, dilation_rate=2, padding='same', activation='relu', name=\"tcn1\")(x)\n",
        "\n",
        "    # Attention leggera (tipo global self-attention)\n",
        "    attention = layers.Permute((2,1), name=\"permute_for_attention\")(x)\n",
        "    attention = layers.Dense(input_shape[0], activation='softmax', name=\"attention_weights\")(attention)\n",
        "    attention = layers.Permute((2,1), name=\"unpermute\")(attention)\n",
        "    x = layers.Multiply(name=\"apply_attention\")([x, attention])\n",
        "\n",
        "    # Pooling e FC finale\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_avg_pool\")(x)\n",
        "    x = layers.Dense(32, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_tdnn_model(input_shape, model_name='TDNN OFDM-DCSK'):\n",
        "    # Dal paper: \"Reliable and Secure Deep Learning-Based OFDM-DCSK Transceiver Design Without Delivery of Reference Chaotic Sequences\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_length = input_shape[0]\n",
        "    x = layers.Reshape((input_length, 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(4, 2, activation='relu', padding='same', name=\"tdnn_conv1\")(x)\n",
        "    x = layers.Conv1D(8, 4, activation='relu', padding='same', name=\"tdnn_conv2\")(x)\n",
        "    x = layers.Conv1D(16, 8, activation='relu', padding='same', name=\"tdnn_conv3\")(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False), name=\"bidirectional_lstm\")(x)\n",
        "    x = layers.Dense(128, name=\"fc1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"batch_norm\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu_fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name='DNN_Aided_Demodulator')\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_mc_dlcs_model(input_shape, model_name='MC-DLCSK'):\n",
        "    # Dal paper: \"A Multi-Carrier Deep Learning CSK Communication System\"\n",
        "    if input_shape[0] % 2 != 0:\n",
        "        raise ValueError(\"input_shape deve essere pari per MC-DLCSK\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_lstm\")(inputs)\n",
        "    x = layers.Bidirectional(layers.LSTM(50, return_sequences=False), name=\"bidirectional_lstm\")(x)\n",
        "    x = layers.Dense(64, activation='relu', name=\"fc1_relu\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_lstm_dnn_model(input_shape, model_name='LSTM_DNN_OFDM_DCSK'):\n",
        "    # Dal paper: \"Intelligent and Reliable Deep Learning LSTM Neural Networks-Based OFDM-DCSK Demodulation Design\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    if len(input_shape) == 1:\n",
        "        x = layers.Reshape((1, input_shape[0]))(inputs)\n",
        "    elif len(input_shape) == 2:\n",
        "        x = inputs\n",
        "    else:\n",
        "        raise ValueError(\"input_shape deve essere 1D o 2D\")\n",
        "    x = layers.LSTM(19, return_sequences=True)(x)\n",
        "    x = layers.TimeDistributed(layers.Dense(38, activation='relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "models_dict = {\n",
        "    \"Ultra-CAN\": get_ultracan_model,\n",
        "    #\"TDNN OFDM-DCSK\": get_tdnn_model,\n",
        "    #\"MC-DLCSK\": get_mc_dlcs_model,\n",
        "    #\"LSTM_DNN_OFDM_DCSK\": get_lstm_dnn_model\n",
        "}"
      ],
      "metadata": {
        "id": "5UoABDP2KlQI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training..."
      ],
      "metadata": {
        "id": "HqhoJHu1Lks5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addestramento\n",
        "for snr_range, datasets in paths.items():\n",
        "    x_train, y_train = load_dataset(datasets['train'])\n",
        "    x_val, y_val = load_dataset(datasets['val'])\n",
        "\n",
        "    for model_name, builder in models_dict.items():\n",
        "        print(f\"\\nAddestramento modello: {model_name} | SNR range: {snr_range}\")\n",
        "        model = builder(input_shape=x_train.shape[1:])\n",
        "\n",
        "        callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "        start_time = time.time() # Registra il tempo di inizio training\n",
        "\n",
        "        model.fit(\n",
        "            x_train, y_train,\n",
        "            validation_data=(x_val, y_val),\n",
        "            epochs=30,\n",
        "            batch_size=32,\n",
        "            callbacks=[callback],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        end_time = time.time() # Registra il tempo di fine training\n",
        "        total_training_time = end_time - start_time\n",
        "\n",
        "        print(f\"Training completato.\")\n",
        "        print(f\"Tempo totale di training: {total_training_time:.2f} secondi.\") # Stampa il tempo totale\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}_rayleigh_snr_{snr_range}.h5\")\n",
        "        model.save(save_path)\n",
        "        print(f\"Salvato modello in: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u1TCwRHLmHk",
        "outputId": "f76dc336-3975-4c7d-9cb1-329a6fb12ad5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/training_0-20_SNR.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_0-20_SNR.npz\n",
            "\n",
            "Addestramento modello: Ultra-CAN | SNR range: 0-20\n",
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.7985 - loss: 0.3874 - val_accuracy: 0.9628 - val_loss: 0.1171\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9655 - loss: 0.1087 - val_accuracy: 0.9683 - val_loss: 0.0988\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9700 - loss: 0.0949 - val_accuracy: 0.9714 - val_loss: 0.0898\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.0828 - val_accuracy: 0.9760 - val_loss: 0.0763\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9764 - loss: 0.0725 - val_accuracy: 0.9754 - val_loss: 0.0750\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9776 - loss: 0.0687 - val_accuracy: 0.9754 - val_loss: 0.0760\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0663 - val_accuracy: 0.9786 - val_loss: 0.0675\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.0630 - val_accuracy: 0.9790 - val_loss: 0.0639\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.0602 - val_accuracy: 0.9807 - val_loss: 0.0575\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0547 - val_accuracy: 0.9803 - val_loss: 0.0549\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0495 - val_accuracy: 0.9809 - val_loss: 0.0507\n",
            "Epoch 12/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0460 - val_accuracy: 0.9809 - val_loss: 0.0483\n",
            "Epoch 13/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0416 - val_accuracy: 0.9802 - val_loss: 0.0508\n",
            "Epoch 14/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0419 - val_accuracy: 0.9818 - val_loss: 0.0469\n",
            "Epoch 15/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0380 - val_accuracy: 0.9825 - val_loss: 0.0457\n",
            "Epoch 16/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0357 - val_accuracy: 0.9816 - val_loss: 0.0470\n",
            "Epoch 17/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0363 - val_accuracy: 0.9811 - val_loss: 0.0519\n",
            "Epoch 18/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0347 - val_accuracy: 0.9820 - val_loss: 0.0542\n",
            "Epoch 19/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0308 - val_accuracy: 0.9758 - val_loss: 0.0663\n",
            "Epoch 20/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0324 - val_accuracy: 0.9806 - val_loss: 0.0551\n",
            "Epoch 21/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9881 - loss: 0.0280 - val_accuracy: 0.9816 - val_loss: 0.0533\n",
            "Epoch 22/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0280 - val_accuracy: 0.9822 - val_loss: 0.0527\n",
            "Epoch 23/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0250 - val_accuracy: 0.9794 - val_loss: 0.0616\n",
            "Epoch 24/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0254 - val_accuracy: 0.9819 - val_loss: 0.0591\n",
            "Epoch 25/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0224 - val_accuracy: 0.9807 - val_loss: 0.0561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 456.61 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks/Ultra-CAN_rayleigh_snr_0-20.h5\n",
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR.npz\n",
            "\n",
            "Addestramento modello: Ultra-CAN | SNR range: 11-15\n",
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.7579 - loss: 0.4131 - val_accuracy: 0.9724 - val_loss: 0.0821\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9757 - loss: 0.0774 - val_accuracy: 0.9739 - val_loss: 0.0764\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9791 - loss: 0.0590 - val_accuracy: 0.9785 - val_loss: 0.0537\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0471 - val_accuracy: 0.9814 - val_loss: 0.0450\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0414 - val_accuracy: 0.9808 - val_loss: 0.0468\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0361 - val_accuracy: 0.9816 - val_loss: 0.0444\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0329 - val_accuracy: 0.9821 - val_loss: 0.0451\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0285 - val_accuracy: 0.9820 - val_loss: 0.0472\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9881 - loss: 0.0278 - val_accuracy: 0.9798 - val_loss: 0.0537\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0259 - val_accuracy: 0.9792 - val_loss: 0.0608\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0254 - val_accuracy: 0.9811 - val_loss: 0.0531\n",
            "Epoch 12/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0241 - val_accuracy: 0.9804 - val_loss: 0.0596\n",
            "Epoch 13/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0216 - val_accuracy: 0.9803 - val_loss: 0.0766\n",
            "Epoch 14/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0206 - val_accuracy: 0.9805 - val_loss: 0.0601\n",
            "Epoch 15/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0174 - val_accuracy: 0.9798 - val_loss: 0.0661\n",
            "Epoch 16/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0169 - val_accuracy: 0.9807 - val_loss: 0.0667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 288.58 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks/Ultra-CAN_rayleigh_snr_11-15.h5\n"
          ]
        }
      ]
    }
  ]
}