{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OEAfQA05D6ua",
        "OBZ65HW9CLdc",
        "ruZPxAV6vU1c",
        "5-OIWzG7KXcF",
        "365gVxtmMCIE",
        "MwvcZ4a6tvz_",
        "5yFgI7DeuVoC",
        "ozKj8KK2iN89",
        "fI9IYcZniSVa",
        "tkgpGoa9DO5L"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "OEAfQA05D6ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import platform\n",
        "from tensorflow.keras import layers, optimizers, losses, models, Input, Model\n",
        "import time # Per misurare il tempo di training\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Per l'early stopping\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Per mostrare una barra di progresso"
      ],
      "metadata": {
        "id": "cAkyZrEzu97V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the HW Specs."
      ],
      "metadata": {
        "id": "OBZ65HW9CLdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Dettagli dell'Architettura Hardware della Sessione Colab ---\\n\")\n",
        "\n",
        "# --- 1. Dettagli CPU ---\n",
        "print(\"--- Dettagli CPU ---\")\n",
        "!lscpu\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 2. Dettagli RAM (Memoria) ---\n",
        "print(\"--- Dettagli RAM (Memoria) ---\")\n",
        "!cat /proc/meminfo | grep MemTotal\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 3. Dettagli Spazio su Disco ---\n",
        "print(\"--- Dettagli Spazio su Disco ---\")\n",
        "!df -h /\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 4. Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
        "print(\"--- Dettagli Acceleratore Hardware (GPU/TPU) ---\")\n",
        "try:\n",
        "    tpu_address = os.environ.get('COLAB_TPU_ADDR')\n",
        "    if tpu_address:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(f\"Tipo Acceleratore: TPU (indirizzo: {tpu_address})\")\n",
        "        print(\"Dispositivi TPU disponibili:\")\n",
        "        for device in tf.config.list_logical_devices('TPU'):\n",
        "            print(f\"  - {device.name}\")\n",
        "    else:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            print(f\"Tipo Acceleratore: GPU\")\n",
        "            for gpu in gpus:\n",
        "                print(f\"  - Dispositivo GPU rilevato: {gpu.name}\")\n",
        "            print(\"\\nDettagli GPU specifici (da `!nvidia-smi`):\")\n",
        "            !nvidia-smi\n",
        "        else:\n",
        "            print(\"Tipo Acceleratore: Nessuna GPU o TPU rilevata (in uso CPU)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Si Ã¨ verificato un errore durante la rilevazione dell'acceleratore: {e}\")\n",
        "    print(\"Tentativo di rilevare i dispositivi TensorFlow standard:\")\n",
        "    devices = tf.config.list_logical_devices()\n",
        "    if devices:\n",
        "        for device in devices:\n",
        "            print(f\"  - Dispositivo rilevato: {device.name}, Tipo: {device.device_type}\")\n",
        "    else:\n",
        "        print(\"Nessun dispositivo TensorFlow rilevato.\")\n",
        "\n",
        "print(\"\\n--- Analisi Dettagli Hardware Completata ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBhq145cCO9I",
        "outputId": "04125fb3-c086-4fa0-dc8a-22fa4171ae8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dettagli dell'Architettura Hardware della Sessione Colab ---\n",
            "\n",
            "--- Dettagli CPU ---\n",
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:           6\n",
            "    Model:                79\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             0\n",
            "    BogoMIPS:             4399.99\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm r\n",
            "                          dseed adx smap xsaveopt arat md_clear arch_capabilitie\n",
            "                          s\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     256 KiB (1 instance)\n",
            "  L3:                     55 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n",
            "\n",
            "\n",
            "--- Dettagli RAM (Memoria) ---\n",
            "MemTotal:       13289416 kB\n",
            "\n",
            "\n",
            "--- Dettagli Spazio su Disco ---\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   38G   70G  36% /\n",
            "\n",
            "\n",
            "--- Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
            "Tipo Acceleratore: Nessuna GPU o TPU rilevata (in uso CPU)\n",
            "\n",
            "--- Analisi Dettagli Hardware Completata ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect To Gdrive to store the datasets created."
      ],
      "metadata": {
        "id": "X46EKvDxpZ-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7J7tQfWpjXc",
        "outputId": "314b2d71-1ea5-4038-b7ae-2cc107956205"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimental Parameters Setting"
      ],
      "metadata": {
        "id": "ruZPxAV6vU1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Parametri di Simulazione di Base ---\n",
        "BETA = 50  # Fattore di spreading (lunghezza della sequenza caotica per simbolo)\n",
        "M = 4      # Numero di sottoportanti\n",
        "X0_INITIAL = 0.9 # Stato iniziale per le mappe caotiche\n",
        "SNR_TRAIN_RANGE_DB = [0, 20] # SNR range for training\n",
        "\n",
        "# Dataset sizes (adjust as needed for computational resources)\n",
        "NUM_SYMBOLS_TRAIN = 105000\n",
        "NUM_SYMBOLS_VALIDATION = 105000\n",
        "\n",
        "CHANNEL_TYPE = 'awgn'\n",
        "L_FADING = 1 # Parametro per Rayleigh fading\n",
        "\n",
        "# --- 1. Impostazione del Seed Globale all'inizio dello script ---\n",
        "# Questo Ã¨ il punto chiave per la riproducibilitÃ  di TUTTO ciÃ² che segue.\n",
        "MASTER_RANDOM_SEED = 42\n",
        "np.random.seed(MASTER_RANDOM_SEED)\n",
        "random.seed(MASTER_RANDOM_SEED) # Imposta anche il seed per la libreria 'random' di Python se la usi\n",
        "tf.random.set_seed(MASTER_RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(MASTER_RANDOM_SEED) # Per operazioni basate su hash (es. ordine dei dizionari)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Forza operazioni deterministiche in TensorFlow 2.x\n"
      ],
      "metadata": {
        "id": "ND4-RdZwvXxc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining signals-related functions."
      ],
      "metadata": {
        "id": "B1KXGelpD9zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Generazione delle Mappe Caotiche ---\n",
        "def bernoulli_map(x0, length):\n",
        "    \"\"\"Genera una sequenza dalla mappa di Bernoulli shift.\"\"\"\n",
        "    sequence = np.zeros(length)\n",
        "    x = x0\n",
        "    for i in range(length):\n",
        "        x = (2 * x) % 1\n",
        "        sequence[i] = x\n",
        "    return sequence\n",
        "\n",
        "def logistic_map(x0, length, rho=3.6):\n",
        "    \"\"\"Genera una sequenza dalla mappa Logistica.\"\"\"\n",
        "    sequence = np.zeros(length)\n",
        "    x = x0\n",
        "    for i in range(length):\n",
        "        x = rho * x * (1 - x)\n",
        "        sequence[i] = x\n",
        "    return sequence\n",
        "\n",
        "# --- 3. Modulazione Multi-Carrier e Simulazione del Canale ---\n",
        "def mc_modulate(chaotic_sequence, M):\n",
        "    \"\"\"\n",
        "    Simula la modulazione multi-carrier replicando la sequenza su M \"sottoportanti\".\n",
        "    \"\"\"\n",
        "    return np.tile(chaotic_sequence, (M, 1)) # M x BETA\n",
        "\n",
        "def add_awgn(signal, snr_db):\n",
        "    \"\"\"Aggiunge rumore AWGN a un segnale complesso.\"\"\"\n",
        "    # Calcola la potenza del segnale (assumendo potenza media)\n",
        "    signal_power = np.mean(np.abs(signal)**2)\n",
        "\n",
        "    # Converte SNR da dB a lineare\n",
        "    snr_linear = 10**(np.array(snr_db) / 10) # Explicitly treat snr_db as scalar\n",
        "\n",
        "    # Calcola la potenza del rumore necessaria\n",
        "    # snr_linear = signal_power / noise_power\n",
        "    noise_power = signal_power / snr_linear\n",
        "\n",
        "    # Genera rumore complesso (parte reale e immaginaria) con potenza corretta\n",
        "    # np.sqrt(noise_power / 2) perchÃ© il rumore Ã¨ distribuito su Re e Im\n",
        "    noise_amplitude = np.sqrt(noise_power / 2)\n",
        "    # print(f\"Noise amplitude shape: {noise_amplitude.shape}\") # Debug print\n",
        "    noise = noise_amplitude * (np.random.randn(*signal.shape) + 1j * np.random.randn(*signal.shape))\n",
        "    return signal + noise\n",
        "\n",
        "def add_rayleigh_fading(signal, snr_db, L=1):\n",
        "    \"\"\"\n",
        "    Aggiunge fading di Rayleigh (L percorsi) e rumore AWGN a un segnale.\n",
        "    Il segnale viene normalizzato dopo il fading per mantenere la potenza media prima del rumore.\n",
        "    Ora applica fading indipendente per ciascuna \"sottoportante\" (riga) se il segnale Ã¨ 2D.\n",
        "    \"\"\"\n",
        "    if signal.ndim == 1: # Caso single carrier, trasforma in 2D per coerenza\n",
        "        num_subcarriers = 1\n",
        "        signal_to_fade = signal[np.newaxis, :]\n",
        "    else: # Caso multi-carrier (M x BETA)\n",
        "        num_subcarriers = signal.shape[0]\n",
        "        signal_to_fade = signal\n",
        "\n",
        "    faded_signal_sum_all_subcarriers = np.zeros_like(signal_to_fade, dtype=complex)\n",
        "\n",
        "    for _ in range(L):\n",
        "        # Genera coefficienti di fading di Rayleigh indipendenti per ciascuna sottoportante\n",
        "        # h sarÃ  una colonna (num_subcarriers, 1) per il broadcast corretto\n",
        "        h = (np.random.randn(num_subcarriers, 1) + 1j * np.random.randn(num_subcarriers, 1)) / np.sqrt(2)\n",
        "        faded_signal_sum_all_subcarriers += h * signal_to_fade\n",
        "\n",
        "    # Normalizza la potenza del segnale dopo il fading per mantenere la potenza del segnale originaria\n",
        "    # prima di aggiungere AWGN e quindi l'SNR calcolato correttamente.\n",
        "    original_signal_power = np.mean(np.abs(signal_to_fade)**2)\n",
        "    current_faded_power = np.mean(np.abs(faded_signal_sum_all_subcarriers)**2)\n",
        "\n",
        "    if current_faded_power > 0:\n",
        "        faded_signal_normalized = faded_signal_sum_all_subcarriers * np.sqrt(original_signal_power / current_faded_power)\n",
        "    else:\n",
        "        faded_signal_normalized = np.zeros_like(signal_to_fade, dtype=complex)\n",
        "\n",
        "    if signal.ndim == 1: # Se l'input originale era 1D, ritorna 1D\n",
        "        faded_signal_normalized = faded_signal_normalized.flatten()\n",
        "\n",
        "    return add_awgn(faded_signal_normalized, snr_db)\n",
        "\n",
        "def form_receiver_input(received_signals_mc, beta):\n",
        "    \"\"\"\n",
        "    Prende i segnali ricevuti dalle M sottoportanti (M x BETA) e forma l'input 2xbeta.\n",
        "    Media dei segnali ricevuti su tutte le M sottoportanti.\n",
        "    \"\"\"\n",
        "    averaged_signal = np.mean(received_signals_mc, axis=0) # Risultato: (BETA,) complex\n",
        "\n",
        "    # Separa parte reale e immaginaria e concatena per formare un vettore 2*beta\n",
        "    input_vector = np.concatenate([np.real(averaged_signal), np.imag(averaged_signal)])\n",
        "    return input_vector"
      ],
      "metadata": {
        "id": "1-EHtaOSAQES"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate datasets function."
      ],
      "metadata": {
        "id": "5-OIWzG7KXcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "snr_db = int(np.random.uniform(0,20+1))\n",
        "# Calcolo l'snr non in decibel ma in SNR\n",
        "snr_linear = 10**(snr_db / 10)\n",
        "print(snr_linear)\n",
        "current_snr_samples_limit = (1/(snr_linear+1))*100000\n",
        "print(current_snr_samples_limit )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j2k3WgHerUc",
        "outputId": "501f596c-36b3-49d1-d534-7e3a3a4e1f99"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9952623149688795\n",
            "33386.05754168779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snr_range = np.arange(0, 20 + 1)  # 0 to 20 dB\n",
        "print(snr_range)\n",
        "# Calcola peso inverso per ogni snr_db\n",
        "weights = np.array([1 / (1 + snr) for snr in snr_range])\n",
        "print(weights)\n",
        "# Normalizza i pesi per ottenere sample totali uguali a TOT\n",
        "weights = weights / weights.sum()\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmFUfSfNt0Wv",
        "outputId": "37c322bd-849e-440c-c344-31607d989510"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
            "[1.         0.5        0.33333333 0.25       0.2        0.16666667\n",
            " 0.14285714 0.125      0.11111111 0.1        0.09090909 0.08333333\n",
            " 0.07692308 0.07142857 0.06666667 0.0625     0.05882353 0.05555556\n",
            " 0.05263158 0.05       0.04761905]\n",
            "[0.27432143 0.13716071 0.09144048 0.06858036 0.05486429 0.04572024\n",
            " 0.03918878 0.03429018 0.03048016 0.02743214 0.02493831 0.02286012\n",
            " 0.02110165 0.01959439 0.0182881  0.01714509 0.01613655 0.01524008\n",
            " 0.01443797 0.01371607 0.01306293]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(num_symbols_train, num_symbols_val,\n",
        "                     snr_train_range_db,\n",
        "                     beta, M, channel_type='AWGN', L=1):\n",
        "    \"\"\"\n",
        "    Genera i dataset completi per training e validation,\n",
        "    e un test set separato per ogni punto SNR specificato.\n",
        "    La riproducibilitÃ  Ã¨ garantita dall'impostazione globale del seed di NumPy\n",
        "    all'inizio dello script.\n",
        "\n",
        "    Args:\n",
        "        num_symbols_train (int): Numero di simboli per il training set.\n",
        "        num_symbols_val (int): Numero di simboli per il validation set.\n",
        "        snr_range_db (list): Lista dei valori di SNR in dB.\n",
        "        beta (float): Parametro per le mappe caotiche.\n",
        "        M (int): Ordine della modulazione.\n",
        "        channel_type (str): Tipo di canale ('AWGN' o 'Rayleigh').\n",
        "        L (int): Parametro per il canale Rayleigh.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, y_train, X_val, y_val, X_test_by_snr, y_test_by_snr)\n",
        "               - X_train, y_train: Dataset di training.\n",
        "               - X_val, y_val: Dataset di validation.\n",
        "               - X_test_by_snr (dict): Dizionario di array NumPy per i dati di test,\n",
        "                                       dove le chiavi sono i valori di SNR.\n",
        "               - y_test_by_snr (dict): Dizionario di array NumPy per le etichette di test,\n",
        "                                       dove le chiavi sono i valori di SNR.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"--- Generazione Dataset per Canale: {channel_type} ---\")\n",
        "\n",
        "    def _generate_single_split(num_symbols, current_snr_config, split_name, fixed_snr=None):\n",
        "        X_data = np.zeros((num_symbols, 2 * beta))\n",
        "        y_labels = np.zeros(num_symbols, dtype=int)\n",
        "\n",
        "        snr_samples_counter = {snr: 0 for snr in range(21)}\n",
        "\n",
        "\n",
        "        for i in tqdm(range(num_symbols), desc=f\"Generating {channel_type} {split_name} Dataset\"):\n",
        "            # Nel caso reale la mappa da scegliere dipende dal simbolo che voglio trasmettere non da np.random.rand()\n",
        "            # Se voglio trasmettere uno 0 allora scelgo la mappa di bernoulli. altrimenti logistic. (e la label deve essere scelta di conseguenza)\n",
        "            map_type = 'bernoulli' if np.random.rand() < 0.5 else 'logistic'\n",
        "            label = 0 if map_type == 'bernoulli' else 1\n",
        "\n",
        "            if fixed_snr is not None:\n",
        "                snr_db = fixed_snr\n",
        "            elif isinstance(current_snr_config, list):\n",
        "                # genera snr_db ma se un punto snr Ã¨ pieno (raggiunto valore: NUM_SYMBOLS_TRAIN/current_snr_config[1]) allora generane altri\n",
        "                snr_db_generated = False\n",
        "                while not snr_db_generated:\n",
        "                    snr_db = int(np.random.uniform(current_snr_config[0], current_snr_config[1]+1))\n",
        "                    # Calcolo l'snr non in decibel ma in SNR\n",
        "                    snr_linear = 10**(snr_db / 10)\n",
        "\n",
        "                    snr_range = np.arange(0, 20 + 1)  # 0 to 20 dB\n",
        "\n",
        "\n",
        "                    # Calcola peso inverso per ogni snr_db\n",
        "                    weights = np.array([1 / (1 + snr) for snr in snr_range])\n",
        "                    # Normalizza i pesi per ottenere sample totali uguali a TOT\n",
        "                    weights = weights / weights.sum()\n",
        "\n",
        "                    current_snr_samples_limit = weights[snr_db]*NUM_SYMBOLS_TRAIN\n",
        "                    if snr_samples_counter[snr_db]<current_snr_samples_limit:\n",
        "                        snr_db_generated = True\n",
        "                        snr_samples_counter[snr_db]+=1\n",
        "                    else:\n",
        "                        continue\n",
        "            else: # Singolo valore SNR\n",
        "                snr_db = current_snr_config\n",
        "\n",
        "            x0_current = np.random.rand()\n",
        "\n",
        "            chaotic_sequence = bernoulli_map(x0_current, beta) if map_type == 'bernoulli' else logistic_map(x0_current, beta)\n",
        "            modulated_signal = mc_modulate(chaotic_sequence, M)\n",
        "\n",
        "            if channel_type == 'AWGN':\n",
        "                received_signal_mc = add_awgn(modulated_signal, snr_db)\n",
        "            elif channel_type == 'Rayleigh':\n",
        "                received_signal_mc = add_rayleigh_fading(modulated_signal, snr_db, L=L)\n",
        "            else:\n",
        "                raise ValueError(\"channel_type deve essere 'AWGN' o 'Rayleigh'\")\n",
        "\n",
        "            X_data[i] = form_receiver_input(received_signal_mc, beta)\n",
        "            y_labels[i] = label\n",
        "        print(\"\\nEcco il dizionario per il conteggio dei sample generati:\" +str(snr_samples_counter))\n",
        "        return X_data, y_labels\n",
        "\n",
        "    # --- Generazione Training Set ---\n",
        "    print(\"\\nInizio generazione Training Set...\")\n",
        "    # Il range SNR per il training Ã¨ 11-15 dB, come indicato nel paper [cite: 115]\n",
        "    # L'SNR per il training Ã¨ una variabile casuale all'interno del range specificato [cite: 114]\n",
        "    X_train, y_train = _generate_single_split(num_symbols_train, snr_train_range_db, \"Train\")\n",
        "    print(\"Training Set generato.\")\n",
        "\n",
        "    # --- Generazione Validation Set ---\n",
        "    print(\"\\nInizio generazione Validation Set...\")\n",
        "    X_val, y_val = _generate_single_split(num_symbols_val, snr_train_range_db, \"Validation\")\n",
        "    print(\"Validation Set generato.\")\n",
        "\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n"
      ],
      "metadata": {
        "id": "ReOpqL69KaRl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Â Generate the dataset for AWGN channel."
      ],
      "metadata": {
        "id": "365gVxtmMCIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path di base su Google Drive\n",
        "base_path = '/content/drive/MyDrive/Academic/2025/Conferences/INFOCOM2026/GitHub/AWGN/dataset'\n",
        "\n",
        "#sequence_lengths = [5, 10, 15, 20, 30]\n",
        "sequence_lengths = [50]\n",
        "for M in sequence_lengths:\n",
        "    print(f\"\\nð Lunghezza sequenza caotica M = {M}\")\n",
        "\n",
        "    # 1. Dataset con SNR da 0 a 20 dB\n",
        "    SNR_TRAIN_RANGE_DB = [0, 20]\n",
        "    X_train_awgn, y_train_awgn, X_val_awgn, y_val_awgn = generate_dataset(\n",
        "        num_symbols_train=NUM_SYMBOLS_TRAIN,\n",
        "        num_symbols_val=NUM_SYMBOLS_VALIDATION,\n",
        "        snr_train_range_db=SNR_TRAIN_RANGE_DB,\n",
        "        beta=BETA,\n",
        "        M=M,\n",
        "        channel_type='AWGN',\n",
        "        L=L_FADING\n",
        "    )\n",
        "\n",
        "    np.savez(os.path.join(base_path, f'AdaLearn_SNR_SAMPLES_training_0-20_SNR_{M}_BETA.npz'),\n",
        "             X_train=X_train_awgn,\n",
        "             y_train=y_train_awgn)\n",
        "    np.savez(os.path.join(base_path, f'AdaLearn_SNR_SAMPLES_validation_0-20_SNR_{M}_BETA.npz'),\n",
        "             X_val=X_val_awgn,\n",
        "             y_val=y_val_awgn)\n",
        "\n",
        "    print(f\"â Dataset M={M} salvati.\")\n",
        "\n",
        "print(\"\\nâ Tutti i dataset sono stati generati e salvati correttamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3u1AoPqsm_c",
        "outputId": "05629d9d-9073-4040-872c-6bebe86d2eaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ð Lunghezza sequenza caotica M = 50\n",
            "--- Generazione Dataset per Canale: AWGN ---\n",
            "\n",
            "Inizio generazione Training Set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating AWGN Train Dataset: 100%|ââââââââââ| 105000/105000 [00:47<00:00, 2196.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ecco il dizionario per il conteggio dei sample generati:{0: 28794, 1: 14402, 2: 9602, 3: 7201, 4: 5761, 5: 4801, 6: 4115, 7: 3601, 8: 3201, 9: 2881, 10: 2619, 11: 2401, 12: 2216, 13: 2058, 14: 1921, 15: 1801, 16: 1695, 17: 1601, 18: 1516, 19: 1441, 20: 1372}\n",
            "Training Set generato.\n",
            "\n",
            "Inizio generazione Validation Set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating AWGN Validation Dataset: 100%|ââââââââââ| 105000/105000 [00:47<00:00, 2229.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ecco il dizionario per il conteggio dei sample generati:{0: 28794, 1: 14402, 2: 9602, 3: 7201, 4: 5761, 5: 4801, 6: 4115, 7: 3601, 8: 3201, 9: 2881, 10: 2619, 11: 2401, 12: 2216, 13: 2058, 14: 1921, 15: 1801, 16: 1695, 17: 1601, 18: 1516, 19: 1441, 20: 1372}\n",
            "Validation Set generato.\n",
            "â Dataset M=50 salvati.\n",
            "\n",
            "â Tutti i dataset sono stati generati e salvati correttamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Â Generate the dataset for Rayleigh channel."
      ],
      "metadata": {
        "id": "dDClj1kqtEjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path di base su Google Drive\n",
        "base_path = '/content/drive/MyDrive/Academic/2025/Conferences/INFOCOM2026/GitHub/Rayleigh/dataset'\n",
        "\n",
        "#sequence_lengths = [5, 10, 15, 20, 30]\n",
        "sequence_lengths = [50]\n",
        "for M in sequence_lengths:\n",
        "    print(f\"\\nð Lunghezza sequenza caotica M = {M}\")\n",
        "\n",
        "    # 1. Dataset con SNR da 0 a 20 dB\n",
        "    SNR_TRAIN_RANGE_DB = [0, 20]\n",
        "    X_train, y_train, X_val, y_val = generate_dataset(\n",
        "        num_symbols_train=NUM_SYMBOLS_TRAIN,\n",
        "        num_symbols_val=NUM_SYMBOLS_VALIDATION,\n",
        "        snr_train_range_db=SNR_TRAIN_RANGE_DB,\n",
        "        beta=BETA,\n",
        "        M=M,\n",
        "        channel_type='Rayleigh',\n",
        "        L=L_FADING\n",
        "    )\n",
        "\n",
        "    np.savez(os.path.join(base_path, f'AdaLearn_SNR_SAMPLES_training_0-20_SNR_{M}_BETA.npz'),\n",
        "             X_train=X_train,\n",
        "             y_train=y_train)\n",
        "    np.savez(os.path.join(base_path, f'AdaLearn_SNR_SAMPLES_validation_0-20_SNR_{M}_BETA.npz'),\n",
        "             X_val=X_val,\n",
        "             y_val=y_val)\n",
        "\n",
        "    print(f\"â Dataset M={M} salvati.\")\n",
        "\n",
        "print(\"\\nâ Tutti i dataset sono stati generati e salvati correttamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asi_D47jtDsJ",
        "outputId": "d86e1c47-649f-43c1-f1de-c0d18bb92b99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ð Lunghezza sequenza caotica M = 50\n",
            "--- Generazione Dataset per Canale: Rayleigh ---\n",
            "\n",
            "Inizio generazione Training Set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Rayleigh Train Dataset: 100%|ââââââââââ| 105000/105000 [00:58<00:00, 1804.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ecco il dizionario per il conteggio dei sample generati:{0: 28794, 1: 14402, 2: 9602, 3: 7201, 4: 5761, 5: 4801, 6: 4115, 7: 3601, 8: 3201, 9: 2881, 10: 2619, 11: 2401, 12: 2216, 13: 2058, 14: 1921, 15: 1801, 16: 1695, 17: 1601, 18: 1516, 19: 1441, 20: 1372}\n",
            "Training Set generato.\n",
            "\n",
            "Inizio generazione Validation Set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Rayleigh Validation Dataset: 100%|ââââââââââ| 105000/105000 [00:58<00:00, 1782.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ecco il dizionario per il conteggio dei sample generati:{0: 28794, 1: 14402, 2: 9602, 3: 7201, 4: 5761, 5: 4801, 6: 4115, 7: 3601, 8: 3201, 9: 2881, 10: 2619, 11: 2401, 12: 2216, 13: 2058, 14: 1921, 15: 1801, 16: 1695, 17: 1601, 18: 1516, 19: 1441, 20: 1372}\n",
            "Validation Set generato.\n",
            "â Dataset M=50 salvati.\n",
            "\n",
            "â Tutti i dataset sono stati generati e salvati correttamente.\n"
          ]
        }
      ]
    }
  ]
}